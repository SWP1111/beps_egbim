import datetime
import logging
import log_config
from flask_jwt_extended import get_jwt_identity, jwt_required
from flask import Blueprint, Response, jsonify, request
from extensions import db, redis_client
from models import PushMessages, Users, ContentRelPages, LearningCompletionHistory
import json
from sqlalchemy import Float, func
from config import Config

api_push_bp = Blueprint('push', __name__)  # ë¸”ë£¨í”„ë¦°íŠ¸ ìƒì„±

# ğŸ”¹ GET /leaning/push/events API (SSE ì—°ê²° ì§€ì )
@api_push_bp.route('/events', methods=['GET'])
@jwt_required(locations=["headers","cookies"])
def events():
    user_id = get_jwt_identity()
    
    def generate():
        pubsub = redis_client.pubsub(ignore_subscribe_messages=True)
        pubsub.subscribe(f"message_alert:{user_id}")
        
        while True:
            message = pubsub.get_message(timeout=15.0)
            if message:
                yield f"data: {message['data']}\n\n"
            else:
                # Send a heartbeat to prevent proxy timeouts
                yield ": heartbeat\n\n"
                
    response = Response(generate(), mimetype='text/event-stream')
    response.headers['Cache-Control'] = 'no-cache'
    response.headers['X-Accel-Buffering'] = 'no'
    return response
    
# ğŸ”¹ POST /leaning/push/send API ë©”ì‹œì§€ í‘¸ì‹œ
@api_push_bp.route('/send', methods=['POST'])
@jwt_required(locations=["headers","cookies"])
def send():
    data = request.get_json()
    filter_type = data.get('filter_type')
    filter_value = data.get('filter_value')
    title = data.get('title','')
    message = data.get('message')
    pointValue = data.get('pointValue',0)
    
    if not filter_type:
        return jsonify({
            'status': 'error',
            'message': 'filter_typeì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤.'
        }), 400
    
    if filter_type != 'all' and not filter_value:
        return jsonify({
            'status': 'error',
            'message': 'filter_valueëŠ” í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤.'
        }), 400
        
    if not message:
        return jsonify({
            'status': 'error',
            'message': 'messageëŠ” í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤.'
        }), 400
    
    query = db.session.query(Users.id).filter(Users.is_deleted == False)
    
    if filter_type == 'company':
        query = query.filter(Users.company == filter_value)
    elif filter_type == 'department':
        parts = filter_value.split('||',1)
        if len(parts) == 2:
            query = query.filter(Users.department == parts[1], Users.company == parts[0])
        else:
            query = query.filter(Users.department == filter_value)
    elif filter_type == 'user':
        query = query.filter(Users.id == filter_value)
    
    user_ids = [user.id for user in query.all()]
    if not user_ids:
        return jsonify({
            'status': 'error',
            'message': 'í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.'
        }), 404
     
    # ì „ì²´ í˜ì´ì§€ ìˆ˜  
    total_pages = db.session.query(func.count(ContentRelPages.id)) \
                            .filter(ContentRelPages.is_deleted == False).scalar() or 0
    if total_pages == 0:
        return jsonify({'status': 'error','message': 'ë“±ë¡ëœ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400
    
    # ì‚¬ìš©ìë³„ ì™„ë£Œ í˜ì´ì§€ ìˆ˜
    completion_threshold = datetime.timedelta(minutes=Config.LEARNING_COMPLETED_MINUTES)
    completed_subq = (
        db.session.query(
            LearningCompletionHistory.user_id.label("user_id"),
            func.count(func.distinct(LearningCompletionHistory.page_id)).label("completed_pages")
        )
        .filter(
            LearningCompletionHistory.user_id.in_(user_ids),
            LearningCompletionHistory.total_duration >= completion_threshold
        )
        .group_by(LearningCompletionHistory.user_id)
        .subquery()
    )

    # ì§„ë„ìœ¨ ì¡°ê±´ ì ìš© (pointValue ë¯¸ë§Œë§Œ)
    filtered_query = (
        db.session.query(Users.id)
        .filter(Users.id.in_(user_ids))
        .outerjoin(completed_subq, completed_subq.c.user_id == Users.id)
        .filter(
            (func.coalesce(completed_subq.c.completed_pages, 0).cast(Float) / total_pages * 100) < pointValue
        )
    )
    
    user_ids = [row.id for row in filtered_query.all()]
    if not user_ids:
        return jsonify({'status': 'error','message': f'ì§„ë„ìœ¨ {pointValue}% ë¯¸ë§Œ ì‚¬ìš©ì ì—†ìŒ'}), 404
                           
    now = datetime.datetime.now(datetime.timezone.utc)
    messages = [
        PushMessages(user_id=uid, title=title, message=message, created_at=now)
        for uid in user_ids
    ]
    db.session.add_all(messages)
    db.session.commit()
    
    for msg in messages:
        # ìƒˆ ë©”ì‹œì§€ë¥¼ ìºì‹œì— ì¶”ê°€
        redis_client.rpush(f"push_cache:{msg.user_id}", json.dumps({
            'id': msg.id,
            'title': title,
            'message': message,     
            'created_at': msg.created_at.isoformat(),
            'user_id': msg.user_id,
            'is_read': msg.is_read
        }))
        
        # ìºì‹œ í¬ê¸°ë¥¼ ì œí•œ
        redis_client.ltrim(f"push_cache:{msg.user_id}", -Config.PUSH_MESSAGE_LIMIT, -1)
        
        # ë§Œë£Œ ì‹œê°„ ì„¤ì •
        redis_client.expire(f"push_cache:{msg.user_id}", 600)
        
        # ìƒˆ ë©”ì‹œì§€ ë„ì°© ì•Œë¦¼ ë°œí–‰
        new_count = redis_client.llen(f"push_cache:{msg.user_id}")
        redis_client.publish(f"message_alert:{msg.user_id}", json.dumps({'count': new_count}))
    
    if user_ids:
        # CTEë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì— ìˆœìœ„ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ìš©ìë³„ë¡œ ìµœì‹  ë©”ì‹œì§€ë¶€í„° ìˆœë²ˆì´ ë§¤ê²¨ì§‘ë‹ˆë‹¤.
        ranked_messages_cte = db.session.query(
            PushMessages.id,
            func.row_number().over(
                partition_by=PushMessages.user_id,
                order_by=PushMessages.created_at.desc()
            ).label('rn')
        ).filter(
            PushMessages.user_id.in_(user_ids)
        ).cte('ranked_messages')

        # ì‚­ì œí•  ë©”ì‹œì§€ IDë¥¼ ì„ íƒí•˜ëŠ” ì„œë¸Œì¿¼ë¦¬ì…ë‹ˆë‹¤.
        # ìˆœë²ˆì´ PUSH_MESSAGE_LIMITë³´ë‹¤ í°, ì¦‰ ì˜¤ë˜ëœ ë©”ì‹œì§€ë“¤ì´ ëŒ€ìƒì…ë‹ˆë‹¤.
        ids_to_delete_subquery = db.session.query(
            ranked_messages_cte.c.id
        ).filter(
            ranked_messages_cte.c.rn > Config.PUSH_MESSAGE_LIMIT
        )

        # ë‹¨ì¼ DELETE ë¬¸ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë“  ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ì‚­ì œí•©ë‹ˆë‹¤.
        delete_stmt = PushMessages.__table__.delete().where(
            PushMessages.id.in_(ids_to_delete_subquery)
        )
        db.session.execute(delete_stmt)
        db.session.commit()

    return jsonify({
        'status': 'success',
        'message': 'í‘¸ì‹œ ì•Œë¦¼ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
    })
    
    
# ğŸ”¹ GET /leaning/push/load API ë©”ì‹œì§€ ë¡œë“œ
@api_push_bp.route('/load', methods=['GET'])
@jwt_required(locations=["headers","cookies"])
def load():
    user_id = get_jwt_identity()
    redis_key = f"push_cache:{user_id}"
    
    
    if redis_client.exists(redis_key):
        redis_client.expire(redis_key, 600)  # Redis í‚¤ì˜ ë§Œë£Œ ì‹œê°„ì„ 10ë¶„ìœ¼ë¡œ ì„¤ì •
        raw_messages = redis_client.lrange(redis_key, 0, -1)
        messages = [json.loads(msg) for msg in raw_messages]
        return jsonify({
            'status': 'success',
            'messages': messages
        })
        
    db_messages = PushMessages.query.filter_by(user_id=user_id).order_by(PushMessages.created_at.desc()).limit(Config.PUSH_MESSAGE_LIMIT).all()
    messages = [msg.to_dict() for msg in db_messages]
    
    if messages:
       for msg in reversed(messages):   # ë©”ì‹œì§€ë¥¼ ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ redisì— ì €ì¥(lpopì€ ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ì‚­ì œ)
           redis_client.rpush(redis_key, json.dumps(msg))
       redis_client.expire(redis_key, 600)  # Redis í‚¤ì˜ ë§Œë£Œ ì‹œê°„ì„ 10ë¶„ìœ¼ë¡œ ì„¤ì •
       redis_client.ltrim(redis_key, -5, -1)  # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
        
    return jsonify({
        'status': 'success',
        'messages': messages
    })

# ğŸ”¹ GET /leaning/push/read API ì½ì€ í‘¸ì‹œ ë©”ì‹œì§€ ì²˜ë¦¬    
@api_push_bp.route('/read', methods=['GET'])
@jwt_required(locations=["headers","cookies"])
def read():
    user_id = get_jwt_identity()
    redis_key = f"push_cache:{user_id}"
    
    if not redis_client.exists(redis_key):
        return jsonify({
            'status': 'error',
            'message': 'ì½ì„ í‘¸ì‹œ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤. /leaning/push/check APIë¥¼ ë¨¼ì € í˜¸ì¶œí•´ì£¼ì„¸ìš”.'
        }), 404
    
    raw_messages = redis_client.lrange(redis_key, 0, -1)
    messages = [json.loads(msg) for msg in raw_messages]
    
    unread_ids = [msg['id'] for msg in messages if not msg.get('is_read')]
    now = datetime.datetime.now(datetime.timezone.utc)
    
    if unread_ids:
        PushMessages.query.filter(
            PushMessages.id.in_(unread_ids),
            PushMessages.user_id == user_id,
            PushMessages.is_read == False
        ).update({
            'is_read': True
        }, synchronize_session=False)
        db.session.commit()
        
    for m in messages:
        if m['id'] in unread_ids:
            m['is_read'] = True
    
    redis_client.delete(redis_key)
    for m in messages:
        redis_client.rpush(redis_key, json.dumps(m))
    redis_client.ltrim(redis_key, -Config.PUSH_MESSAGE_LIMIT, -1)
    redis_client.expire(redis_key, 600)

# ğŸ”¹ GET /leaning/push/count API í‘¸ì‹œ ë©”ì‹œì§€ ê°œìˆ˜ í™•ì¸   
@api_push_bp.route('/count', methods=['GET'])
@jwt_required(locations=["headers","cookies"])
def count():
    user_id = get_jwt_identity()
    redis_key = f"push_cache:{user_id}"
    
    if redis_client.exists(redis_key):
        count = redis_client.llen(redis_key)
        return jsonify({
            'status': 'success',
            'count': count
        })
    else:
        return jsonify({
            'status': 'not_loaded',
            'message': '/leaning/push/load APIë¥¼ ë¨¼ì € í˜¸ì¶œí•´ì£¼ì„¸ìš”.',
            'count': 0
        }), 404